{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -r requirements.txt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run train.py\n",
    "\n",
    "Follow the instructions in the blog post to setup your data set and run intial training: blog.paperspace.com/damaged-car-parts-detection-using-yolov8n-an-end-t/ "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!python train.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test model for verification"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "img_pth = \"1.jpeg\"\n",
    "model = YOLO(\"best.pt\") \n",
    "results = model(source=img_pth)\n",
    "res_plotted = results[0].plot()\n",
    "cv2.imshow(\"result\", res_plotted)\n",
    "cv2.waitKey(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Streamlit deployment"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import streamlit as st\n",
    "import torch\n",
    "from PIL import Image, ImageDraw\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = attempt_load('path/to/model.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Load input image\n",
    "image = Image.open('path/to/image.jpg').convert('RGB')\n",
    "\n",
    "# Resize image\n",
    "image_size = 640\n",
    "image = letterbox(image, new_shape=image_size)[0]\n",
    "\n",
    "# Convert image to tensor\n",
    "image = torch.Tensor(image).unsqueeze(0)\n",
    "\n",
    "# Perform inference\n",
    "output = model(image)[0]\n",
    "\n",
    "# Perform non-maximum suppression to remove overlapping detections\n",
    "output = non_max_suppression(output, conf_thres=0.5, iou_thres=0.5)\n",
    "\n",
    "# Draw bounding boxes on the input image\n",
    "draw = ImageDraw.Draw(image)\n",
    "for detection in output[0]:\n",
    "    x1, y1, x2, y2, conf, cls = detection.cpu().numpy()\n",
    "    draw.rectangle([(x1, y1), (x2, y2)], outline=(255, 0, 0), width=3)\n",
    "    draw.text((x1, y1 - 20), f'{int(conf*100)}% {cls}', fill=(255, 0, 0))\n",
    "\n",
    "# Display input and output images\n",
    "st.image([image, output_image], width=300)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deployment with FastAPI\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%cd my_fastapi_app\n",
    "!python main.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Code frontend\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!apt-get update && apt-get install nodejs\n",
    "!curl -L https://npmjs.org/install.sh | sudo sh \n",
    "!npx create-react-app frontend\n",
    "!npm install axios"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now, we need to run both our front end and backend\n",
    "\n",
    "You may need to create another notebook file or terminal window to run main.py and app.js at the same time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!npm run start"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}